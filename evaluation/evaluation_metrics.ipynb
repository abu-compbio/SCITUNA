{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import rpy2\n",
    "import scib\n",
    "import scanpy\n",
    "import scipy\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rpy2 import robjects\n",
    "from IPython.utils import io\n",
    "from tqdm  import tqdm as tqdm\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>StrVector with 9 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            'lisi'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'tools'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'stats'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            ...\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'datasets'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'methods'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'base'\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.StrVector object at 0x7fb9cd90d550> [RTYPES.STRSXP]\n",
       "R classes: ('character',)\n",
       "['lisi', 'tools', 'stats', 'graphics', ..., 'utils', 'datasets', 'methods', 'base']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R library(lisi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"small_atac_peaks\" \n",
    "data_keys={\"human_lung_atlas\":{\"batch_key\":\"batch\",\"label_key\":\"cell_type\"},\n",
    "           \"human_pancreas\":{\"batch_key\":\"tech\",\"label_key\":\"celltype\"},\n",
    "           \"small_atac_peaks\":{\"batch_key\":\"batchname\",\"label_key\":\"final_cell_label\"},\n",
    "           \"small_atac_windows\":{\"batch_key\":\"batchname\",\"label_key\":\"final_cell_label\"}}\n",
    "methods = ['SCITUNA', 'Scanorama', 'fastMNN', 'Seurat', 'SAUCIE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Original Datasets (unintegrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/h5ad.py:238: OldFormatWarning: Element '/layers' was written without encoding metadata.\n",
      "  d[k] = read_elem(f[k])\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/batchname' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/batchname' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/batchname_all' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/batchname_all' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/final_cell_label' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/final_cell_label' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/obs/_index' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/var/_index' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/n_cells-0-0' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/commonness-0-0' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/prop_shared_cells-0-0' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/variability_score-0-0' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/n_cells-1-0' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/commonness-1-0' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/prop_shared_cells-1-0' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/variability_score-1-0' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/n_cells-1' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/commonness-1' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/prop_shared_cells-1' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/variability_score-1' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/raw/var/_index' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset\")\n",
    "unintegrated_data=scanpy.read_h5ad(\"../data/{}.h5ad\".format(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Batch Pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are : 3  batch pairs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('10x Genomics', 'Cusanovich et al.'),\n",
       " ('10x Genomics', 'Fang et al.'),\n",
       " ('Cusanovich et al.', 'Fang et al.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreive batch pairs as tuples\n",
    "batch_pairs = [(a,b) for idx, a in enumerate(np.unique(unintegrated_data.obs[data_keys[dataset][\"batch_key\"]])) for b in np.unique(unintegrated_data.obs[data_keys[dataset][\"batch_key\"]])[idx + 1:]]\n",
    "print(\"There are :\",len(batch_pairs),\" batch pairs.\")\n",
    "batch_pairs[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_alias = {\n",
    "    'NMI_cluster/label':           \"NMI cluster/label\",\n",
    "    'ARI_cluster/label':           \"ARI cluster/label\",\n",
    "    'ASW_label':                   \"Cell type ASW\",\n",
    "    'isolated_label_F1':           \"Isolated label F1\",\n",
    "    'isolated_label_silhouette':   \"Isolated label silhouette\", \n",
    "    'cell_cycle_conservation':     \"CC conservation\",\n",
    "    'hvg_overlap':                 \"HVG conservation\", \n",
    "    'cLISI':                       \"cLISI\",\n",
    "    'PCR_batch':                   \"PCR batch\",\n",
    "    'ASW_label/batch':             \"Batch ASW\",\n",
    "    'iLISI':                       \"iLISI\",\n",
    "    'graph_conn':                  \"Graph connectivity\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overcorrection_score(emb, celltype, n_neighbors=100, n_pools=100, n_samples_per_pool=100, seed=124):\n",
    "    \"\"\"\n",
    "    source: https://doi.org/10.1038/s41467-022-33758-z\n",
    "    \"\"\"\n",
    "    n_neighbors = min(n_neighbors, len(emb) - 1)\n",
    "    nne = NearestNeighbors(n_neighbors=1 + n_neighbors, n_jobs=8)\n",
    "    nne.fit(emb)\n",
    "    kmatrix = nne.kneighbors_graph(emb) - scipy.sparse.identity(emb.shape[0])\n",
    "\n",
    "    score = 0\n",
    "    celltype_ = np.unique(celltype)\n",
    "    celltype_dict = celltype.value_counts().to_dict()\n",
    "    \n",
    "    N_celltype = len(celltype_)\n",
    "\n",
    "    for t in range(n_pools):\n",
    "        indices = np.random.choice(np.arange(emb.shape[0]), size=n_samples_per_pool, replace=False)\n",
    "        score += np.mean([np.mean(celltype[kmatrix[i].nonzero()[1]][:min(celltype_dict[celltype[i]], n_neighbors)] == celltype[i]) for i in indices])\n",
    "\n",
    "    return 1-score / float(n_pools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scib_metrics(m_path, unintegrated_data):\n",
    "    \n",
    "    #check if file is empty or corrupted\n",
    "    if os.stat(m_path).st_size == 0:\n",
    "        print(f'{m_path} is empty, setting all metrics to NA.')\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        #integrated data\n",
    "        adata_int = scanpy.read(m_path, cache=True)\n",
    "        #anndata object of the data before integration\n",
    "        adata_pre=unintegrated_data[adata_int.obs_names]\n",
    "\n",
    "    #check if the number of genes in the integrated dataset is less than the desired number of HVG\n",
    "    if (n_hvgs is not None):\n",
    "        if (adata_int.n_vars < n_hvgs):\n",
    "            raise ValueError(\"There are less genes in the corrected adata than specified for HVG selection\")\n",
    "\n",
    "\n",
    "\n",
    "    # check input files\n",
    "    if adata_pre.n_obs != adata_int.n_obs:\n",
    "        print(\"Error detected: Observations\")\n",
    "        message = \"The datasets have different numbers of cells before and after integration.\"\n",
    "        message += \"Please make sure that both datasets match.\"\n",
    "        raise ValueError(message)\n",
    "\n",
    "    # check if the obsnames were changed and rename them in that case\n",
    "    if len(set(adata_pre.obs_names).difference(set(adata_int.obs_names))) > 0:\n",
    "        print(\"Error detected: Observation Mames\")\n",
    "        # rename adata_int.obs[batch_key] labels by overwriting them with the pre-integration labels\n",
    "        new_obs_names = ['-'.join(idx.split('-')[:-1]) for idx in adata_int.obs_names]\n",
    "\n",
    "        if len(set(adata_pre.obs_names).difference(set(new_obs_names))) == 0:\n",
    "            adata_int.obs_names = new_obs_names\n",
    "        else:\n",
    "            raise ValueError('obs_names changed after integration!')\n",
    "\n",
    "    # batch_key might be overwritten, so we match it to the pre-integrated labels\n",
    "    adata_int.obs[data_keys[dataset][\"batch_key\"]] = adata_int.obs[data_keys[dataset][\"batch_key\"]].astype('category')\n",
    "    batch_u = adata_pre.obs[data_keys[dataset][\"batch_key\"]].value_counts().index\n",
    "    batch_i = adata_int.obs[data_keys[dataset][\"batch_key\"]].value_counts().index\n",
    "    if not batch_i.equals(batch_u):\n",
    "        # pandas uses the table index to match the correct labels\n",
    "        adata_int.obs[data_keys[dataset][\"batch_key\"]] = adata_pre.obs[data_keys[dataset][\"batch_key\"]]\n",
    "\n",
    "\n",
    "    #with io.capture_output() as captured:\n",
    "    with io.capture_output() as captured:\n",
    "        scib.preprocessing.reduce_data(\n",
    "            adata_int,\n",
    "            n_top_genes=n_hvgs,\n",
    "            neighbors=True,\n",
    "            use_rep='X_pca',\n",
    "            pca=True,\n",
    "            umap=False\n",
    "        )\n",
    "\n",
    "    #print(\"| Batch & Bio metrics\",end=\"\\t\")\n",
    "\n",
    "    # DEFAULT\n",
    "    silhouette_ = True\n",
    "    nmi_ = True\n",
    "    ari_ = True\n",
    "    pcr_ = True\n",
    "    cell_cycle_ = True\n",
    "    isolated_labels_ = True\n",
    "    hvg_score_ = True\n",
    "    graph_conn_ = True\n",
    "\n",
    "    if assay == \"simulation\":\n",
    "        cell_cycle_ = False\n",
    "    elif assay == \"atac\":\n",
    "        cell_cycle_ = False\n",
    "        hvg_score_ = False\n",
    "\n",
    "\n",
    "    with io.capture_output() as captured:\n",
    "        metrics = scib.me.metrics(\n",
    "            adata_pre,\n",
    "            adata_int,\n",
    "            verbose=False,\n",
    "            hvg_score_=hvg_score_,\n",
    "            cluster_nmi=None,\n",
    "            batch_key=data_keys[dataset][\"batch_key\"],\n",
    "            label_key=data_keys[dataset][\"label_key\"],\n",
    "            silhouette_=silhouette_,\n",
    "            nmi_=nmi_,\n",
    "            nmi_method='arithmetic',\n",
    "            nmi_dir=None,\n",
    "            ari_=ari_,\n",
    "            pcr_=pcr_,\n",
    "            cell_cycle_=cell_cycle_,\n",
    "            organism=organism,\n",
    "            isolated_labels_=isolated_labels_,\n",
    "            n_isolated=None,\n",
    "            graph_conn_=graph_conn_,\n",
    "            kBET_=False,\n",
    "            lisi_graph_=False,\n",
    "            trajectory_=False\n",
    "        )\n",
    "\n",
    "    ###### Calculate iLISI, cLISI ######\n",
    "    #print(\"| LISI\",end=\"\\t\")\n",
    "    integrated_df=adata_int.to_df()\n",
    "    celltypes_df=pd.DataFrame(adata_int.obs[data_keys[dataset][\"label_key\"]].loc[integrated_df.index])\n",
    "    batches_df=pd.DataFrame(adata_int.obs[data_keys[dataset][\"batch_key\"]].loc[integrated_df.index])\n",
    "    %R -i integrated_df,celltypes_df,batches_df\n",
    "    %R cLISI=lisi::compute_lisi(integrated_df, data.frame(celltypes_df), colnames(celltypes_df))\n",
    "    %R iLISI=lisi::compute_lisi(integrated_df, data.frame(batches_df), colnames(batches_df))\n",
    "    %R -o cLISI,iLISI\n",
    "\n",
    "\n",
    "    #scale ilISI score\n",
    "    nbatches = adata_pre.obs[data_keys[dataset][\"batch_key\"]].nunique()\n",
    "    scaled_ilisi = (np.nanmean(iLISI) - 1) / (nbatches - 1)\n",
    "    metrics[0][\"iLISI\"]=scaled_ilisi\n",
    "\n",
    "\n",
    "    #scale clISI score\n",
    "    nlabs = adata_pre.obs[data_keys[dataset][\"label_key\"]].nunique()\n",
    "    scaled_clisi = (nlabs - np.nanmean(cLISI)) / (nlabs - 1)\n",
    "    metrics[0][\"cLISI\"]=scaled_clisi\n",
    "    ####################################\n",
    "\n",
    "\n",
    "    ##############Over correction\n",
    "    #print(\"| OC\",end=\"\\t\")\n",
    "    scanpy.pp.neighbors(adata_int)\n",
    "    scanpy.tl.umap(adata_int, min_dist=0.1)\n",
    "    metrics.loc[\"1 - Over correction\"] = 1. - overcorrection_score(adata_int.obsm[\"X_umap\"], adata_int.obs[data_keys[dataset][\"label_key\"]])\n",
    "    ####################################\n",
    "\n",
    "    #print(\"| Save..\",end=\"\\n\")\n",
    "    metrics.columns=[pair]\n",
    "    metrics.rename( index=metric_alias, inplace=True)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_hvgs = 2000\n",
    "organism = \"human\" # human | mouse \n",
    "assay = \"atac\" # expression | atac | simulation\n",
    "version = \"pairwise\" # pairwise | MBI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                  | 0/3 [00:00<?, ?it/s]2025-02-13 22:03:22.641680: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-02-13 22:03:22.641761: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-02-13 22:03:23.929010: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-02-13 22:03:23.929145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-02-13 22:03:23.929162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 2/3 [18:08<09:01, 541.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Your filename has more than two extensions: ['.]_[Fang et al', '.]', '.h5ad'].\n",
      "Only considering the two last: ['.]', '.h5ad'].\n",
      "WARNING: Your filename has more than two extensions: ['.]_[Fang et al', '.]', '.h5ad'].\n",
      "Only considering the two last: ['.]', '.h5ad'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [25:37<00:00, 512.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCITUNA (15, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "o_folder=f\"../output/{dataset}/{version}/\"\n",
    "try:\n",
    "    os.mkdir(f\"{o_folder}/metrics/\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if version == \"pairwise\":\n",
    "    combined_metrics = {}\n",
    "    num = 0\n",
    "    for pair in tqdm(batch_pairs):\n",
    "        for method in methods[:1]:\n",
    "            if not  os.path.isfile(f\"{o_folder}/{method}_[{pair[0]}]_[{pair[1]}].h5ad\"):\n",
    "                continue\n",
    "\n",
    "            if os.path.isfile(f\"{o_folder}/metrics/{method}_[{pair[0]}]_[{pair[1]}].csv\"):\n",
    "                continue\n",
    "\n",
    "            if method not in combined_metrics:\n",
    "                combined_metrics[method] = None\n",
    "\n",
    "            m_path=f\"{o_folder}/{method}_[{pair[0]}]_[{pair[1]}].h5ad\"\n",
    "            metrics = scib_metrics(m_path, unintegrated_data)\n",
    "            \n",
    "            if combined_metrics[method] is None:\n",
    "                combined_metrics[method] = metrics\n",
    "            else:\n",
    "                combined_metrics[method] = pd.concat([combined_metrics[method], metrics], axis = 1)\n",
    "\n",
    "            metrics.to_csv(f\"{o_folder}/metrics/{method}_[{pair[0]}]_[{pair[1]}].csv\")\n",
    "            \n",
    "    for method in combined_metrics:            \n",
    "        print(method, combined_metrics[method].shape)\n",
    "        combined_metrics[method].to_csv(f\"{o_folder}/{method}_metrics.csv\")  \n",
    "    \n",
    "    \n",
    "elif version == \"MBI\":\n",
    "     for method in tqdm(methods[:1]):\n",
    "        if not  os.path.isfile(f\"{o_folder}/{method}.h5ad\"):\n",
    "            continue\n",
    "\n",
    "        if os.path.isfile(f\"{o_folder}/metrics/{method}.csv\"):\n",
    "            continue\n",
    "            \n",
    "        m_path=f\"{o_folder}/{method}.h5ad\"\n",
    "        metrics = scib_metrics(m_path, unintegrated_data)\n",
    "        metrics.to_csv(f\"{o_folder}/metrics/{method}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scib-pipeline-R3.6A",
   "language": "python",
   "name": "scib-pipeline-r3.6a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
