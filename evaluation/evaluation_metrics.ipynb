{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import rpy2\n",
    "import scib\n",
    "import scanpy\n",
    "import scipy\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rpy2 import robjects\n",
    "from IPython.utils import io\n",
    "from tqdm  import tqdm as tqdm\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>StrVector with 9 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            'lisi'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'tools'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'stats'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            ...\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'datasets'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'methods'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'base'\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.StrVector object at 0x7f8e6790b3c0> [RTYPES.STRSXP]\n",
       "R classes: ('character',)\n",
       "['lisi', 'tools', 'stats', 'graphics', ..., 'utils', 'datasets', 'methods', 'base']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R library(lisi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"lung\" # \"lung\" or \"pancreas\"\n",
    "#map data objects into batch/lebel keys\n",
    "data_keys={\"lung\":{\"batch_key\":\"batch\",\"label_key\":\"cell_type\", \"file_name\": \"lung_unintegrated\"},\n",
    "           \"pancreas\":{\"batch_key\":\"tech\",\"label_key\":\"celltype\", \"file_name\": \"pancreas_unintegrated\"}}\n",
    "methods = ['SciTuna', 'Scanorama', 'fastMNN', 'Seurat', 'SAUCIE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Original Datasets (unintegrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/h5ad.py:238: OldFormatWarning: Element '/layers' was written without encoding metadata.\n",
      "  d[k] = read_elem(f[k])\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/dataset' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/dataset' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/location' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/location' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/obs/nGene' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/obs/nUMI' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/patientGroup' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/patientGroup' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/obs/percent.mito' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/protocol' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/protocol' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/sanger_type' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/sanger_type' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/obs/size_factors' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/sampling_method' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/sampling_method' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/batch' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/batch' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/cell_type' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/cell_type' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:584: OldFormatWarning: Element '/obs/__categories/donor' was written without encoding metadata.\n",
      "  categories = read_elem(categories_dset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:587: OldFormatWarning: Element '/obs/donor' was written without encoding metadata.\n",
      "  read_elem(dataset), categories, ordered=ordered\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/obs/index' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n",
      "/media/mllab/SSD/anaconda3F/envs/scib-pipeline-R3.6A/lib/python3.7/site-packages/anndata/_io/specs/methods.py:590: OldFormatWarning: Element '/var/index' was written without encoding metadata.\n",
      "  return read_elem(dataset)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset\")\n",
    "unintegrated_data=scanpy.read_h5ad(\"data/{}.h5ad\".format(data_keys[dataset][\"file_name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Batch Pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are : 120  batch pairs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1_2', '1_3', '1_4', '1_5']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreive batch pairs as tuples\n",
    "batch_pairs = [\"{}_{}\".format(a,b) for idx, a in enumerate(np.unique(unintegrated_data.obs[data_keys[dataset][\"batch_key\"]])) for b in np.unique(unintegrated_data.obs[data_keys[dataset][\"batch_key\"]])[idx + 1:]]\n",
    "print(\"There are :\",len(batch_pairs),\" batch pairs.\")\n",
    "batch_pairs[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_map={\n",
    "    'NMI_cluster/label':           \"NMI cluster/label\",\n",
    "    'ARI_cluster/label':           \"ARI cluster/label\",\n",
    "    'ASW_label':                   \"Cell type ASW\",\n",
    "    'isolated_label_F1':           \"Isolated label F1\",\n",
    "    'isolated_label_silhouette':   \"Isolated label silhouette\", \n",
    "    'cell_cycle_conservation':     \"CC conservation\",\n",
    "    'hvg_overlap':                 \"HVG conservation\", \n",
    "    'cLISI':                       \"cLISI\",\n",
    "    'PCR_batch':                   \"PCR batch\",\n",
    "    'ASW_label/batch':             \"Batch ASW\",\n",
    "    'iLISI':                       \"iLISI\",\n",
    "    'graph_conn':                  \"Graph connectivity\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overcorrection_score(emb, celltype, n_neighbors=100, n_pools=100, n_samples_per_pool=100, seed=124):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    n_neighbors = min(n_neighbors, len(emb) - 1)\n",
    "    nne = NearestNeighbors(n_neighbors=1 + n_neighbors, n_jobs=8)\n",
    "    nne.fit(emb)\n",
    "    kmatrix = nne.kneighbors_graph(emb) - scipy.sparse.identity(emb.shape[0])\n",
    "\n",
    "    score = 0\n",
    "    celltype_ = np.unique(celltype)\n",
    "    celltype_dict = celltype.value_counts().to_dict()\n",
    "    \n",
    "    N_celltype = len(celltype_)\n",
    "\n",
    "    for t in range(n_pools):\n",
    "        indices = np.random.choice(np.arange(emb.shape[0]), size=n_samples_per_pool, replace=False)\n",
    "        score += np.mean([np.mean(celltype[kmatrix[i].nonzero()[1]][:min(celltype_dict[celltype[i]], n_neighbors)] == celltype[i]) for i in indices])\n",
    "\n",
    "    return 1-score / float(n_pools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hvg=2000\n",
    "organism=\"human\"\n",
    "assay=\"expression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "outputs_folder=\"output/{}\".format(dataset)\n",
    "combined_metrics = {}\n",
    "num = 0\n",
    "for pair in batch_pairs[:40]:\n",
    "    num+=1\n",
    "    print(\"{} | {}\".format(num, pair))\n",
    "    for method in methods:\n",
    "        if os.path.isfile(\"{}/{}/metrics/{}.csv\".format(outputs_folder, pair, method)):\n",
    "            continue\n",
    "        if method not in combined_metrics:\n",
    "            combined_metrics[method] = None\n",
    "        print(\"\\t\\t\",method, end=\"\\t\")\n",
    "        m_path=\"{}/{}/integrated/{}.h5ad\".format(outputs_folder,pair,method)\n",
    "        #check if file is empty or corrupted\n",
    "        if os.stat(m_path).st_size == 0:\n",
    "            print(f'{m_path} is empty, setting all metrics to NA.')\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            #integrated data\n",
    "            adata_int = scanpy.read(m_path, cache=True)\n",
    "            #anndata object of the data before integration\n",
    "            adata_pre=unintegrated_data[adata_int.obs_names]\n",
    "\n",
    "        #check if the number of genes in the integrated dataset is less than the desired number of HVG\n",
    "        if (hvg is not None):\n",
    "            if (adata_int.n_vars < hvg):\n",
    "                raise ValueError(\"There are less genes in the corrected adata than specified for HVG selection\")\n",
    "\n",
    "\n",
    "\n",
    "        # check input files\n",
    "        if adata_pre.n_obs != adata_int.n_obs:\n",
    "            print(\"Error detected: Observations\")\n",
    "            message = \"The datasets have different numbers of cells before and after integration.\"\n",
    "            message += \"Please make sure that both datasets match.\"\n",
    "            raise ValueError(message)\n",
    "\n",
    "        # check if the obsnames were changed and rename them in that case\n",
    "        if len(set(adata_pre.obs_names).difference(set(adata_int.obs_names))) > 0:\n",
    "            print(\"Error detected: Observation Mames\")\n",
    "            # rename adata_int.obs[batch_key] labels by overwriting them with the pre-integration labels\n",
    "            new_obs_names = ['-'.join(idx.split('-')[:-1]) for idx in adata_int.obs_names]\n",
    "\n",
    "            if len(set(adata_pre.obs_names).difference(set(new_obs_names))) == 0:\n",
    "                adata_int.obs_names = new_obs_names\n",
    "            else:\n",
    "                raise ValueError('obs_names changed after integration!')\n",
    "\n",
    "\n",
    "\n",
    "        # batch_key might be overwritten, so we match it to the pre-integrated labels\n",
    "        adata_int.obs[data_keys[dataset][\"batch_key\"]] = adata_int.obs[data_keys[dataset][\"batch_key\"]].astype('category')\n",
    "        batch_u = adata_pre.obs[data_keys[dataset][\"batch_key\"]].value_counts().index\n",
    "        batch_i = adata_int.obs[data_keys[dataset][\"batch_key\"]].value_counts().index\n",
    "        if not batch_i.equals(batch_u):\n",
    "            # pandas uses the table index to match the correct labels\n",
    "            adata_int.obs[data_keys[dataset][\"batch_key\"]] = adata_pre.obs[data_keys[dataset][\"batch_key\"]]\n",
    "\n",
    "\n",
    "\n",
    "        #with io.capture_output() as captured:\n",
    "        with io.capture_output() as captured:\n",
    "            scib.preprocessing.reduce_data(\n",
    "                adata_int,\n",
    "                n_top_genes=hvg,\n",
    "                neighbors=True,\n",
    "                use_rep='X_pca',\n",
    "                pca=True,\n",
    "                umap=False\n",
    "            )\n",
    "\n",
    "        print(\"| Batch & Bio metrics\",end=\"\\t\")\n",
    "        # DEFAULT\n",
    "        silhouette_ = True\n",
    "        nmi_ = True\n",
    "        ari_ = True\n",
    "        pcr_ = True\n",
    "        cell_cycle_ = True\n",
    "        isolated_labels_ = True\n",
    "        hvg_score_ = True\n",
    "        graph_conn_ = True\n",
    "        kBET_ = False\n",
    "        lisi_graph_ = False\n",
    "        with io.capture_output() as captured:\n",
    "            metrics = scib.me.metrics(\n",
    "                adata_pre,\n",
    "                adata_int,\n",
    "                verbose=False,\n",
    "                hvg_score_=hvg_score_,\n",
    "                cluster_nmi=None,\n",
    "                batch_key=data_keys[dataset][\"batch_key\"],\n",
    "                label_key=data_keys[dataset][\"label_key\"],\n",
    "                silhouette_=silhouette_,\n",
    "                nmi_=nmi_,\n",
    "                nmi_method='arithmetic',\n",
    "                nmi_dir=None,\n",
    "                ari_=ari_,\n",
    "                pcr_=pcr_,\n",
    "                cell_cycle_=cell_cycle_,\n",
    "                organism=organism,\n",
    "                isolated_labels_=isolated_labels_,\n",
    "                n_isolated=None,\n",
    "                graph_conn_=graph_conn_,\n",
    "                kBET_=kBET_,\n",
    "                lisi_graph_=False,\n",
    "                trajectory_=False\n",
    "            )\n",
    "\n",
    "        ###### Calculate iLISI, cLISI ######\n",
    "        print(\"| LISI\",end=\"\\t\")\n",
    "        integrated_df=adata_int.to_df()\n",
    "        celltypes_df=pd.DataFrame(adata_int.obs[data_keys[dataset][\"label_key\"]].loc[integrated_df.index])\n",
    "        batches_df=pd.DataFrame(adata_int.obs[data_keys[dataset][\"batch_key\"]].loc[integrated_df.index])\n",
    "        %R -i integrated_df,celltypes_df,batches_df\n",
    "        %R cLISI=lisi::compute_lisi(integrated_df, data.frame(celltypes_df), colnames(celltypes_df))\n",
    "        %R iLISI=lisi::compute_lisi(integrated_df, data.frame(batches_df), colnames(batches_df))\n",
    "        %R -o cLISI,iLISI\n",
    "\n",
    "\n",
    "        #scale ilISI score\n",
    "        nbatches = adata_pre.obs[data_keys[dataset][\"batch_key\"]].nunique()\n",
    "        scaled_ilisi = (np.nanmean(iLISI) - 1) / (nbatches - 1)\n",
    "        metrics[0][\"iLISI\"]=scaled_ilisi\n",
    "\n",
    "\n",
    "        #scale clISI score\n",
    "        nlabs = adata_pre.obs[data_keys[dataset][\"label_key\"]].nunique()\n",
    "        scaled_clisi = (nlabs - np.nanmean(cLISI)) / (nlabs - 1)\n",
    "        metrics[0][\"cLISI\"]=scaled_clisi\n",
    "        ####################################\n",
    "\n",
    "\n",
    "        ##############Over correction\n",
    "        print(\"| OC\",end=\"\\t\")\n",
    "        scanpy.pp.neighbors(adata_int)\n",
    "        scanpy.tl.umap(adata_int, min_dist=0.1)\n",
    "        metrics.loc[\"1 - Over correction\"] = 1. - overcorrection_score(adata_int.obsm[\"X_umap\"], adata_int.obs[data_keys[dataset][\"label_key\"]])\n",
    "        ####################################\n",
    "\n",
    "        print(\"| Save..\",end=\"\\n\")\n",
    "        metrics.columns=[pair]\n",
    "        metrics.rename( index=scores_map, inplace=True)\n",
    "        if combined_metrics[method] is None:\n",
    "            combined_metrics[method] = metrics\n",
    "        else:\n",
    "            combined_metrics[method] = pd.concat([combined_metrics[method], metrics], axis = 1)\n",
    "        try:\n",
    "            os.mkdir(\"{}/{}/metrics/\".format(outputs_folder, pair))\n",
    "        except:\n",
    "            pass\n",
    "        metrics.to_csv(\"{}/{}/metrics/{}.csv\".format(outputs_folder, pair, method))\n",
    "for method in combined_metrics:            \n",
    "    print(method, combined_metrics[method].shape)\n",
    "    combined_metrics[method].to_csv(\"{}/{}_metrics.csv\".format(outputs_folder, method))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scib-pipeline-R3.6A",
   "language": "python",
   "name": "scib-pipeline-r3.6a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
